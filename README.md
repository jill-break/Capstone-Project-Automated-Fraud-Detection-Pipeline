# Capstone Project: Automated Fraud Detection Pipeline

**Author:** Courage Dei  
**Course:** Applied AI & Prompt Engineering  
**Status:** Completed

## Project Overview
This project implements a **Multi-Stage AI Workflow** designed to automate the detection of fraudulent financial transactions. It solves the problem of manual data review by integrating:
1.  **Chat AI (ChatGPT):** To generate complex statistical SQL logic.
2.  **Database (PostgreSQL):** To execute Z-Score analysis on raw transaction data.
3.  **CLI Tool (Gemini AI):** To ingest the data and generate a natural language fraud alert report.

The pipeline effectively filters thousands of transactions to identify only statistically significant anomalies (Z-Score > 2) without manual intervention.

---

## Workflow Diagram
The following flowchart illustrates the automated data pipeline, from logic generation to the final API-driven analysis.

```mermaid
flowchart TD
    %% Define Styles
    classDef ai fill:#e1f5fe,stroke:#01579b,stroke-width:2px;
    classDef db fill:#fff3e0,stroke:#e65100,stroke-width:2px;
    classDef file fill:#f3e5f5,stroke:#4a148c,stroke-width:2px,stroke-dasharray: 5 5;
    classDef term fill:#212121,stroke:#000,stroke-width:2px,color:#fff;

    %% Nodes
    User([User / Data Engineer])
    
    subgraph Phase1 [Phase 1: Logic Generation]
        ChatAI(Chat AI: ChatGPT)
        Prompt[Context-Rich Prompt]
    end

    subgraph Phase2 [Phase 2: Execution Engine]
        SQL[Complex SQL Query\nWindow Functions & Z-Score]
        DB[(PostgreSQL DB\nDocker Container)]
        Export(Data Export Command)
    end

    subgraph Phase3 [Phase 3: Automated Analysis]
        CSV[/anomalies.csv\nRaw Data/]
        Gemini_Tool(Custom CLI Wrapper\nPython + Google GenAI SDK)
        Report[Final Fraud Alert\nGenerated by Gemini 1.5]
    end

    %% Connections
    User -->|Defines Logic| Prompt
    Prompt --> ChatAI
    ChatAI -->|Generates| SQL
    SQL -->|Executed on| DB
    DB -->|Filters Anomalies| Export
    Export -->|Pipes Output| CSV
    CSV -->|Input Stream| Gemini_Tool
    Gemini_Tool -->|API Call| Report

    %% Apply Styles
    class ChatAI,Gemini_Tool ai;
    class DB,SQL db;
    class CSV,Report file;
    class Export term;

```

---

## Setup Instructions

### 1. Start the Database Container

Run the following command to spin up a PostgreSQL instance in Docker:

```bash
docker-compose up -d

```

### 2. Initialize the Schema & Dummy Data

Log into the container and set up the `transactions` table.

**Step A: Enter the Postgres Shell**

```bash
docker exec -it capstone-db psql -U postgres

```

**Step B: Run the Setup SQL**
Paste the following SQL into the shell to create the table and insert the fraud scenario (User 101's $5,000 purchase):

```sql
CREATE TABLE transactions (
    transaction_id SERIAL PRIMARY KEY,
    user_id INT,
    amount DECIMAL(10, 2),
    transaction_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    merchant_category VARCHAR(50)
);

-- Normal Behavior
INSERT INTO transactions (user_id, amount, merchant_category, transaction_date) VALUES 
(101, 45.50, 'Groceries', NOW() - INTERVAL '10 days'),
(101, 52.00, 'Dining', NOW() - INTERVAL '9 days'),
(101, 60.25, 'Groceries', NOW() - INTERVAL '7 days'),
(101, 55.00, 'Utilities', NOW() - INTERVAL '5 days');

-- The ANOMALY (Fraud)
INSERT INTO transactions (user_id, amount, merchant_category, transaction_date) VALUES 
(101, 5000.00, 'Electronics', NOW() - INTERVAL '1 hour');

-- Other Users
INSERT INTO transactions (user_id, amount, merchant_category, transaction_date) VALUES 
(102, 120.00, 'Retail', NOW() - INTERVAL '3 days');

```

---

##  How to Run the Pipeline

### Phase 1: Logic Generation (Reference)

The SQL logic used in Phase 2 was generated by ChatGPT using the following prompt:

> *"Write a PostgreSQL query to detect anomalies using a Z-Score model. Calculate the average and standard deviation for each user_id and filter for transactions where the Z-Score > 2."*

### Phase 2: Execute & Export Data

Run this command to execute the SQL logic inside the container and export the results to a local CSV file. This filters the data to only show suspicious transactions.

**Command:**

```powershell
docker exec -i capstone-db psql -U postgres -d postgres -c "COPY (SELECT transaction_id, user_id, amount, transaction_date, merchant_category, (amount - AVG(amount) OVER (PARTITION BY user_id)) / STDDEV_SAMP(amount) OVER (PARTITION BY user_id) as z_score FROM transactions) TO STDOUT WITH CSV HEADER" > anomalies.csv

```

### Phase 3: Automated CLI Analysis (Gemini AI)

To fulfill the requirement for a "CLI AI" tool, I implemented a custom Python wrapper that interfaces with the **Google Gemini API**.

The raw CSV data is piped from standard input (stdin) into the script, which constructs a prompt and sends it to the Gemini model. The model interprets the Z-scores and generates a natural language assessment of the fraud risk.

**Command:**

```bash
cat anomalies.csv | python scripts/gemini_cli.py

```

**Output:**

* **Console:** Displays the real-time analysis from Gemini.
* **File:** Saves a permanent record to `fraud_report.md`.

---

## Project Screenshots

Below is the visual proof of execution for each stage of the pipeline.

### Environment Setup

**Docker Container Initialization**
![Project Screenshots](src/Project%20Screenshots/1%20-%20Docker%20initialization.png)

**Database Running in Docker**
![Project Screenshots](src/Project%20Screenshots/2%20-%20Database%20running%20in%20Docker.png)

**Schema Creation & Data Insertion**
![Project Screenshots](src/Project%20Screenshots/3%20-%20Database%20table%20create%20and%20insert.png)

### Pipeline Execution

**Gemini CLI Script Execution**
![Project Screenshots](src/Project%20Screenshots/CLI%20Prompt.png)

**Final Anomaly Report Output (1)**
![Project Screenshots](src/Project%20Screenshots/6%20-%20Anomaly%20report%201.png)

**Final Anomaly Report Output (2)**
![Project Screenshots](src/Project%20Screenshots/7%20-%20Anomaly%20report%202.png)
---

##  Adaptability Note

Originally designed to use the GitHub Copilot CLI. Due to the recent deprecation of the tool, this workflow was adapted to use a custom Python analyzer powered by the Google Gemini API. This ensures the pipeline remains robust and tool-agnostic.



